{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TrFK1vHJZ0M",
        "outputId": "3aa52f5a-b757-40be-ee74-7d0ddb774f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyresparser\n",
            "  Downloading pyresparser-1.0.6-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (23.1.0)\n",
            "Requirement already satisfied: blis>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.7.11)\n",
            "Requirement already satisfied: certifi>=2019.6.16 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2023.11.17)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (5.2.0)\n",
            "Requirement already satisfied: cymem>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.0.8)\n",
            "Collecting docx2txt>=0.7 (from pyresparser)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.6)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.19.2)\n",
            "Requirement already satisfied: nltk>=3.4.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.5.3)\n",
            "Collecting pdfminer.six>=20181108 (from pyresparser)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: preshed>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.0.9)\n",
            "Collecting pycryptodome>=3.8.2 (from pyresparser)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent>=0.15.2 (from pyresparser)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2019.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2023.3.post1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.31.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.4.0)\n",
            "Requirement already satisfied: spacy>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.6.1)\n",
            "Requirement already satisfied: srsly>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.4.8)\n",
            "Requirement already satisfied: thinc>=7.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (8.1.12)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.66.1)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.0.7)\n",
            "Requirement already satisfied: wasabi>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.1.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.15.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (41.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from preshed>=2.0.1->pyresparser) (1.0.10)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (1.0.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (3.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc>=7.0.4->pyresparser) (0.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.1.4->pyresparser) (2.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (2.21)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=6d7b7e17a51e91d2ee8deff9fc003f1095b9f79c16a10263c780902c5e7d6b28\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt, pyrsistent, pycryptodome, pdfminer.six, pyresparser\n",
            "Successfully installed docx2txt-0.8 pdfminer.six-20221105 pycryptodome-3.19.0 pyresparser-1.0.6 pyrsistent-0.20.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyresparser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez7PKwx-QKMR",
        "outputId": "ac1279a6-678e-4e82-855f-ce4ceab092cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer3\n",
            "  Downloading pdfminer3-2018.12.3.0.tar.gz (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from pdfminer3) (3.19.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer3) (2.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from pdfminer3) (5.2.0)\n",
            "Building wheels for collected packages: pdfminer3\n",
            "  Building wheel for pdfminer3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfminer3: filename=pdfminer3-2018.12.3.0-py3-none-any.whl size=117808 sha256=ae856e5e6d6fb59ca6dd08c7b87c6badba0e4fff18cadf9beeabaa59c2df775c\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/71/87/7a05ed89df2d26f343b71bcc89c8257fdfc1541a79d79736c2\n",
            "Successfully built pdfminer3\n",
            "Installing collected packages: pdfminer3\n",
            "Successfully installed pdfminer3-2018.12.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKJBwN_fxUFm",
        "outputId": "def762a6-56bc-4909-a29b-3a57f5ab20ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time,datetime\n",
        "import io\n",
        "from pyresparser import ResumeParser\n",
        "from pdfminer3.layout import LAParams\n",
        "from pdfminer3.pdfpage import PDFPage\n",
        "from pdfminer3.pdfinterp import PDFResourceManager\n",
        "from pdfminer3.pdfinterp import PDFPageInterpreter\n",
        "from pdfminer3.converter import TextConverter"
      ],
      "metadata": {
        "id": "MHPytLs-PqJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf(file):\n",
        "  rm=PDFResourceManager()\n",
        "  fke_file=io.StringIO()\n",
        "  converter=TextConverter(rm,fke_file,laparams=LAParams())\n",
        "  page_intrepeter=PDFPageInterpreter(rm,converter)\n",
        "  with open(file,\"rb\") as fh:\n",
        "    for page in PDFPage.get_pages(fh,caching=True,check_extractable=True):\n",
        "      page_intrepeter.process_page(page)\n",
        "      print(page)\n",
        "    text=fke_file.getvalue()\n",
        "  converter.close()\n",
        "  fke_file.close()\n",
        "  return text"
      ],
      "metadata": {
        "id": "rHVvcTqkP228"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=pdf(\"/content/drive/MyDrive/SJBIT/resumes/2.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_miihAPrREsX",
        "outputId": "ab8ef0f5-01ac-4e8b-d31c-b6ce603890a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PDFPage: Resources={'ProcSet': [/'PDF', /'Text', /'ImageB', /'ImageC', /'ImageI'], 'ExtGState': {'G3': <PDFObjRef:4>, 'G10': <PDFObjRef:5>}, 'XObject': {'X4': <PDFObjRef:6>, 'X11': <PDFObjRef:7>, 'X13': <PDFObjRef:9>, 'X15': <PDFObjRef:11>, 'X17': <PDFObjRef:13>, 'X19': <PDFObjRef:15>}, 'Font': {'F5': <PDFObjRef:17>, 'F6': <PDFObjRef:22>, 'F7': <PDFObjRef:27>, 'F8': <PDFObjRef:32>, 'F9': <PDFObjRef:37>}}, MediaBox=[0, 0, 612, 792]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=d.split(\"\\n\")"
      ],
      "metadata": {
        "id": "NAjkHUsm_Y_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=\" \".join(c)\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "dzucc9U_SAnV",
        "outputId": "0c66cfd0-8329-4409-becc-98adfee1eece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"+91 6360760866 Bengaluru, KA hemanthvokkaliga2003@gmail.com https://github.com/Hemanth-j www.linkedin.com/in/HemanthGowda19  SUMMARY Strong in design and integration with intuitive problem-solving skills. Proﬁcient in Machine Learning, Deep Learning, Python and SQL. Ability to translate business requirements into technical solutions. Looking to start the career as an software engineer with a reputed ﬁrm driven by technology. EDUCATION  Bengaluru, KA  B.Tech in Computer Science Engineering REVA University CGPA: 9.4/10 12/2020 - Present Pre-University (PCMB) KLE Independent PU College CGPA: 9.54/10 03/2018 - 03/2020 SSLC (KSEEB) St Paul's High School CGPA: 9.2/10 03/2006 - 05/2018  Bengaluru, KA  Bengaluru, KA  EXPERIENCE  Project Trainee Intern ( 06/2023 - present) Bosch Global Software Technologies - Bengaluru, KA  ● Worked in MS/ECZ4-XC department. ● Developed Python scripts to automate manual  testing in Infotainment systems under the Suzuki DA3 project.  ● Currently into the SX/EHC1 department as a ML intern, where I am working on developing LLMs that can be used as an internal ChatGPT for our company.  AI Backend Developer Intern ( 08/2022 - 11/2022) Karmaa Labs - Bengaluru, KA  ● Built intelligence systems, created API's, and  deployed them using Django.  HEMANTH J  B.Tech CSE PROJECTS Vehicle Theft Detection System  ● Developed software that is capable of detecting stolen vehicles  whenever the owner ﬁles a complaint against his lost vehicle on our website.  ● Technologies: MERN, Computer Vision, Yolo, ML/DL, Python,  Google Colab, OCR, TensorFlow.  Safe Rides  ● Developed a system to monitor the driver during driving vehicles  to prevent vehicle accidents.  ● Technologies: HTML, CSS, Computer Vision, DLib, ML/DL,Python,  Android Studio, TensorFlow, Sinch SMS API.  Coconut disease detection using CNN  ● Developed a model to identify various Coconut diseases with  98% accuracy for Tata Institute for Research(TIFR). ● Technologies: Computer Vision,CNN, ML/DL, Python,  TensorFlow, Google Colab.  Face Recognition based Door Unlocking System  ● Using deep learning, we developed a model to identify people  and unlock the door automatically.  ● Technologies: Computer Vision,DLib, ML/DL, Python, TensorFlow, Google Colab, Arduino Uno, Servo Motor.  SKILLS  ● Languages  Python, JAVA, SQL, HTML/CSS.  ● Frameworks  Django (Basics), Tensorﬂow, Scikit-Learn.  ● Tools  MongoDB, MYSQL, IBMdb2, Linux, Windows.  ● Soft Skills  Time Management, Communication, Creativity, Problem Solving, Leadership, Collaboration.  ACHIEVEMENTS AND CERTIFICATIONS  ● Python for Everybody Specialization  University of Michigan - COURSERA  ● IBM Data Analyst Professional Certiﬁcate  IBM - COURSERA  ● AI, ML, DL Master Class Workshop  Pantech Prolabs India Pvt Ltd  ● Complete Machine learning with Python  Rob Percival - Udemy  ● BOSCH AI Competition Winner (Globally) ● Top 3 Teams of Hackaphasia (AI Hackathon) ● Top 10 Teams of REVA HACK 2021 ● Hack 4 Mysore Hackathon Winner (Mit)  \\x0c\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GoogleBard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxeroxivxCNc",
        "outputId": "6e7f0ff4-4c9a-4851-b589-eeeb8ebd0e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GoogleBard\n",
            "  Downloading GoogleBard-2.1.0-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.10/dist-packages (from GoogleBard) (3.0.43)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from GoogleBard) (13.7.0)\n",
            "Collecting httpx[socks] (from GoogleBard)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->GoogleBard) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->GoogleBard) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx[socks]->GoogleBard)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->GoogleBard) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->GoogleBard) (1.3.0)\n",
            "Collecting socksio==1.* (from httpx[socks]->GoogleBard)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx[socks]->GoogleBard)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit->GoogleBard) (0.2.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->GoogleBard) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->GoogleBard) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->GoogleBard) (0.1.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[socks]->GoogleBard) (1.2.0)\n",
            "Installing collected packages: socksio, h11, httpcore, httpx, GoogleBard\n",
            "Successfully installed GoogleBard-2.1.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 socksio-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bardapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XclQj1hFyxFm",
        "outputId": "f12c9897-4d32-468c-bf75-d931895f00c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bardapi\n",
            "  Downloading bardapi-0.1.38-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: httpx[http2]>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from bardapi) (0.26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bardapi) (2.31.0)\n",
            "Collecting deep-translator (from bardapi)\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from bardapi)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: google-cloud-translate in /usr/local/lib/python3.10/dist-packages (from bardapi) (3.11.3)\n",
            "Collecting browser-cookie3 (from bardapi)\n",
            "  Downloading browser_cookie3-0.19.1-py3-none-any.whl (14 kB)\n",
            "Collecting langdetect (from bardapi)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (1.3.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->bardapi)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx[http2]>=0.20.0->bardapi) (0.14.0)\n",
            "Collecting lz4 (from browser-cookie3->bardapi)\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from browser-cookie3->bardapi)\n",
            "  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jeepney in /usr/lib/python3/dist-packages (from browser-cookie3->bardapi) (0.7.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator->bardapi) (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bardapi) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bardapi) (2.0.7)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-translate->bardapi) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-translate->bardapi) (2.3.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-translate->bardapi) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-translate->bardapi) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->bardapi) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator->bardapi) (2.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate->bardapi) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate->bardapi) (2.17.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate->bardapi) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate->bardapi) (1.48.2)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->bardapi)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->bardapi)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[http2]>=0.20.0->bardapi) (1.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate->bardapi) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate->bardapi) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate->bardapi) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-translate->bardapi) (0.5.1)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=4df581d7763561b1e9447e98b13dcfe433507dc0e87cd5636362499a793dca69\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: pycryptodomex, lz4, langdetect, hyperframe, hpack, colorama, h2, deep-translator, browser-cookie3, bardapi\n",
            "Successfully installed bardapi-0.1.38 browser-cookie3-0.19.1 colorama-0.4.6 deep-translator-1.11.4 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 langdetect-1.0.9 lz4-4.3.2 pycryptodomex-3.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "d=re.sub(r\"https?:\\/\\/?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w\\.-])*\",\"\",d)\n",
        "d=re.sub(r\"\\S+@\\S+\",\"\",d)\n",
        "d=re.sub(r\"[^a-zA-Z0-9\\s]\",\"\",d)\n",
        "d=re.sub(r\"\\s+\",\" \",d).strip()\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "WDksfSBYHvfC",
        "outputId": "5a93f50a-3574-4164-fc59-3f30af1e6ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'91 6360760866 Bengaluru KA wwwlinkedincominHemanthGowda19 SUMMARY Strong in design and integration with intuitive problemsolving skills Procient in Machine Learning Deep Learning Python and SQL Ability to translate business requirements into technical solutions Looking to start the career as an software engineer with a reputed rm driven by technology EDUCATION Bengaluru KA BTech in Computer Science Engineering REVA University CGPA 9410 122020 Present PreUniversity PCMB KLE Independent PU College CGPA 95410 032018 032020 SSLC KSEEB St Pauls High School CGPA 9210 032006 052018 Bengaluru KA Bengaluru KA EXPERIENCE Project Trainee Intern 062023 present Bosch Global Software Technologies Bengaluru KA Worked in MSECZ4XC department Developed Python scripts to automate manual testing in Infotainment systems under the Suzuki DA3 project Currently into the SXEHC1 department as a ML intern where I am working on developing LLMs that can be used as an internal ChatGPT for our company AI Backend Developer Intern 082022 112022 Karmaa Labs Bengaluru KA Built intelligence systems created APIs and deployed them using Django HEMANTH J BTech CSE PROJECTS Vehicle Theft Detection System Developed software that is capable of detecting stolen vehicles whenever the owner les a complaint against his lost vehicle on our website Technologies MERN Computer Vision Yolo MLDL Python Google Colab OCR TensorFlow Safe Rides Developed a system to monitor the driver during driving vehicles to prevent vehicle accidents Technologies HTML CSS Computer Vision DLib MLDLPython Android Studio TensorFlow Sinch SMS API Coconut disease detection using CNN Developed a model to identify various Coconut diseases with 98 accuracy for Tata Institute for ResearchTIFR Technologies Computer VisionCNN MLDL Python TensorFlow Google Colab Face Recognition based Door Unlocking System Using deep learning we developed a model to identify people and unlock the door automatically Technologies Computer VisionDLib MLDL Python TensorFlow Google Colab Arduino Uno Servo Motor SKILLS Languages Python JAVA SQL HTMLCSS Frameworks Django Basics Tensorow ScikitLearn Tools MongoDB MYSQL IBMdb2 Linux Windows Soft Skills Time Management Communication Creativity Problem Solving Leadership Collaboration ACHIEVEMENTS AND CERTIFICATIONS Python for Everybody Specialization University of Michigan COURSERA IBM Data Analyst Professional Certicate IBM COURSERA AI ML DL Master Class Workshop Pantech Prolabs India Pvt Ltd Complete Machine learning with Python Rob Percival Udemy BOSCH AI Competition Winner Globally Top 3 Teams of Hackaphasia AI Hackathon Top 10 Teams of REVA HACK 2021 Hack 4 Mysore Hackathon Winner Mit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bardapi.constants import SESSION_HEADERS\n",
        "from bardapi import Bard\n",
        "\n",
        "token = \"eQhsM9VxajgLFOp_EQg02Km3XGi8qZwsESd6XWc4YFGynEg7fI2sCncxQOJXNyQdu5dfUg.\"\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers = SESSION_HEADERS\n",
        "session.cookies.set(\"__Secure-1PSID\", token)\n",
        "session.cookies.set(\"__Secure-1PSIDTS\", \"sidts-CjIBPVxjSqTKyunnGWc0nsavyXa0ThSjq_oM2lSqPlHXMlMnEo-CeE3v5zhBLKh44c-O4hAA\")\n",
        "session.cookies.set(\"__Secure-1PSIDCC\", \"ABTWhQEjmCfLE5asUG6JfE9lRuprZgN1GY9a8HuXUussfm6MLDg8Vs5woK7ZEbvd5wOri-0OU9s\")\n",
        "\n",
        "bard = Bard(token=token, session=session)"
      ],
      "metadata": {
        "id": "RSzrWtxjxBZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(context1, context2):\n",
        "    vectorizer = CountVectorizer().fit_transform([context1, context2])\n",
        "    vectors = vectorizer.toarray()\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity = cosine_similarity(vectors[0].reshape(1, -1), vectors[1].reshape(1, -1))\n",
        "\n",
        "    return similarity[0][0]\n",
        "\n",
        "context1 = d\n",
        "context2 = \"\"\"Proven experience as a Data Scientist or Data Analyst\n",
        "Experience in data mining\n",
        "Understanding of machine-learning and operations research\n",
        "Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset\n",
        "Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)\n",
        "Analytical mind and business acumen\n",
        "Strong math skills (e.g. statistics, algebra)\n",
        "Problem-solving aptitude\n",
        "Excellent communication and presentation skills\n",
        "BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred\"\"\"\n",
        "similarity_score = calculate_cosine_similarity(context1, context2)\n",
        "print(f\"Cosine Similarity Score: {similarity_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_r_w_9sMuYD",
        "outputId": "557b404c-f671-45c5-ffa5-6ff66107eb3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity Score: 0.30199637753583763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ques=\"\"\"for the given context return the answer in the json format, \"where basic info,Education, Experience, skills\" are mandotary sections :: \\n \"\"\"+str(d)"
      ],
      "metadata": {
        "id": "c2dkBHC88MzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "QIRC9WN-8jDU",
        "outputId": "4245f980-44cd-4a8b-b779-2e5db9c0e7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for the given context return the answer in the json format, \"where basic info,Education, Experience, skills\" are mandotary sections :: \\n PRASHANT SHARMA Computer Science Engineering Student 919103657179 sharmaprashant1584gmailcom SJB Institute of Technology Bengaluru Bachelor of Engineering in Computer Science and Engineering CGPA 802 Education Infant Jesus Hr Sec School Hiranagar Class 12th Marks 806 Infant Jesus Hr Sec School Hiranagar Class 10th Marks 886 Courses 2020 Present 2019 2020 2017 2018 OOPs Data Structures and Algorithms Operating System Database Management System Computer Networks Programming Languages C C Java Python JavaScript Web Development Markup Languages HTML CSS Skills Technologies Used Git GitHub VS Code SQL Window OS Linux OS MacOS OS Projects Personal Portfolio HTML CSS and JS This is my personal portfolio website and I have used HTML CSS and JS to create this project One of the key features of this project is its ability to store inputs from the Connect with Me form in an Excel sheet Spotify Clone HTML CSS and JS This project is a Spotify clone a music player I have created this project using HTML CSS and JavaScript The main feature of this project is that it has various JavaScript event listeners such as click timeupdate and change I have used the play and pause functions of JavaScript to control the playback and pausing of the music Amazon Clone HTML and CSS This is an Amazon clone project and I have used HTML and CSS to create it I have created this project to practice various CSS properties like margin padding exbox and grid layout etc AICTE JK PMSSS Beneciary Achievements Languages Hindi Native English Procient I am a learner who enjoys learning new things daily I have learned many things in the past and continue to learn new things related to technologies and my personal development Summary'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=bard.get_answer(ques)[\"content\"]"
      ],
      "metadata": {
        "id": "ztPkkoRn79Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "VTtR59_YCMrc",
        "outputId": "8607a87b-3bbc-448e-fd8b-35ab75312c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"basic info\": {\\n    \"name\": \"Prashant Sharma\",\\n    \"email\": \"sharmaprashant1584gmailcom\",\\n    \"phone\": \"+919103657179\",\\n    \"location\": \"Bengaluru, India\"\\n  },\\n  \"Education\": {\\n    \"SJB Institute of Technology\": {\\n      \"degree\": \"Bachelor of Engineering in Computer Science and Engineering\",\\n      \"cgpa\": 8.02,\\n      \"courses\": [\\n        \"OOPs\",\\n        \"Data Structures and Algorithms\",\\n        \"Operating System\",\\n        \"Database Management System\",\\n        \"Computer Networks\",\\n        \"Programming Languages (C, C++, Java, Python, JavaScript)\"\\n      ]\\n    },\\n    \"Infant Jesus Hr Sec School\": {\\n      \"12th\": {\\n        \"marks\": 80.6\\n      },\\n      \"10th\": {\\n        \"marks\": 88.6\\n      }\\n    }\\n  },\\n  \"Experience\": {},\\n  \"Skills\": {\\n    \"technical\": {\\n      \"programming languages\": [\"C\", \"C++\", \"Java\", \"Python\", \"JavaScript\"],\\n      \"web development\": [\"HTML\", \"CSS\", \"JavaScript\"],\\n      \"markup languages\": [\"HTML\", \"CSS\"],\\n      \"databases\": [\"SQL\"],\\n      \"operating systems\": [\"Windows\", \"Linux\", \"MacOS\"]\\n    },\\n    \"tools\": {\\n      \"Git\": \"Yes\",\\n      \"GitHub\": \"Yes\",\\n      \"VS Code\": \"Yes\"\\n    },\\n    \"languages\": {\\n      \"Hindi\": \"Native\",\\n      \"English\": \"Proficient\"\\n    }\\n  },\\n  \"Projects\": {\\n    \"Personal Portfolio\": {\\n      \"description\": \"A personal portfolio website built with HTML, CSS, and JS. Key features include storing inputs from a contact form in an Excel sheet.\",\\n      \"technologies\": [\"HTML\", \"CSS\", \"JavaScript\"]\\n    },\\n    \"Spotify Clone\": {\\n      \"description\": \"A music player web app built with HTML, CSS, and JavaScript. Features include various JavaScript event listeners for playback control.\",\\n      \"technologies\": [\"HTML\", \"CSS\", \"JavaScript\"]\\n    },\\n    \"Amazon Clone\": {\\n      \"description\": \"An Amazon clone project built with HTML and CSS to practice various CSS properties.\",\\n      \"technologies\": [\"HTML\", \"CSS\"]\\n    }\\n  },\\n  \"Summary\": \"I am a Computer Science Engineering student with a passion for learning new technologies. I have experience in web development using HTML, CSS, and JavaScript, and I am proficient in programming languages like C, C++, Java, Python, and JavaScript. I am also a quick learner and I am always eager to take on new challenges.\"\\n}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "si=z.find(\"{\")\n",
        "if si !=-1:\n",
        "  se=z.rfind(\"}\")\n",
        "  subs=z[si:se+1].strip()\n",
        "  print(subs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkZbwy6f8CSv",
        "outputId": "00868136-6201-451c-86ac-e22f61cd891d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"basic info\": {\n",
            "    \"name\": \"Prashant Sharma\",\n",
            "    \"email\": \"sharmaprashant1584gmailcom\",\n",
            "    \"phone\": \"+919103657179\",\n",
            "    \"location\": \"Bengaluru, India\"\n",
            "  },\n",
            "  \"Education\": {\n",
            "    \"SJB Institute of Technology\": {\n",
            "      \"degree\": \"Bachelor of Engineering in Computer Science and Engineering\",\n",
            "      \"cgpa\": 8.02,\n",
            "      \"courses\": [\n",
            "        \"OOPs\",\n",
            "        \"Data Structures and Algorithms\",\n",
            "        \"Operating System\",\n",
            "        \"Database Management System\",\n",
            "        \"Computer Networks\",\n",
            "        \"Programming Languages (C, C++, Java, Python, JavaScript)\"\n",
            "      ]\n",
            "    },\n",
            "    \"Infant Jesus Hr Sec School\": {\n",
            "      \"12th\": {\n",
            "        \"marks\": 80.6\n",
            "      },\n",
            "      \"10th\": {\n",
            "        \"marks\": 88.6\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"Experience\": {},\n",
            "  \"Skills\": {\n",
            "    \"technical\": {\n",
            "      \"programming languages\": [\"C\", \"C++\", \"Java\", \"Python\", \"JavaScript\"],\n",
            "      \"web development\": [\"HTML\", \"CSS\", \"JavaScript\"],\n",
            "      \"markup languages\": [\"HTML\", \"CSS\"],\n",
            "      \"databases\": [\"SQL\"],\n",
            "      \"operating systems\": [\"Windows\", \"Linux\", \"MacOS\"]\n",
            "    },\n",
            "    \"tools\": {\n",
            "      \"Git\": \"Yes\",\n",
            "      \"GitHub\": \"Yes\",\n",
            "      \"VS Code\": \"Yes\"\n",
            "    },\n",
            "    \"languages\": {\n",
            "      \"Hindi\": \"Native\",\n",
            "      \"English\": \"Proficient\"\n",
            "    }\n",
            "  },\n",
            "  \"Projects\": {\n",
            "    \"Personal Portfolio\": {\n",
            "      \"description\": \"A personal portfolio website built with HTML, CSS, and JS. Key features include storing inputs from a contact form in an Excel sheet.\",\n",
            "      \"technologies\": [\"HTML\", \"CSS\", \"JavaScript\"]\n",
            "    },\n",
            "    \"Spotify Clone\": {\n",
            "      \"description\": \"A music player web app built with HTML, CSS, and JavaScript. Features include various JavaScript event listeners for playback control.\",\n",
            "      \"technologies\": [\"HTML\", \"CSS\", \"JavaScript\"]\n",
            "    },\n",
            "    \"Amazon Clone\": {\n",
            "      \"description\": \"An Amazon clone project built with HTML and CSS to practice various CSS properties.\",\n",
            "      \"technologies\": [\"HTML\", \"CSS\"]\n",
            "    }\n",
            "  },\n",
            "  \"Summary\": \"I am a Computer Science Engineering student with a passion for learning new technologies. I have experience in web development using HTML, CSS, and JavaScript, and I am proficient in programming languages like C, C++, Java, Python, and JavaScript. I am also a quick learner and I am always eager to take on new challenges.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9IvKHmfwB4OK",
        "outputId": "af8a5b32-4dfe-4094-d72e-a81a25341072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "j=json.loads(subs)\n",
        "f=j[\"Skills\"]\n",
        "r2=\"\"\"[,{\\}\\[\\]:\\']\"\"\"\n",
        "f=re.sub(r2,\"\",str(f))\n",
        "f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcT5Of9IBkhT",
        "outputId": "1e84583a-397b-4201-e254-1c348f03dcac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'technical programming languages C C++ Java Python JavaScript web development HTML CSS JavaScript markup languages HTML CSS databases SQL operating systems Windows Linux MacOS tools Git Yes GitHub Yes VS Code Yes languages Hindi Native English Proficient'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jd2=\"Python Java Machine Learning Deep Learning C C++ JAVAScript\""
      ],
      "metadata": {
        "id": "fj5FzN0mOZXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cosine_similarity(context1, context2):\n",
        "    vectorizer = CountVectorizer().fit_transform([context1, context2])\n",
        "    vectors = vectorizer.toarray()\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity = cosine_similarity(vectors[0].reshape(1, -1), vectors[1].reshape(1, -1))\n",
        "\n",
        "    return similarity[0][0]\n",
        "similarity_score = calculate_cosine_similarity(f, jd2)\n",
        "print(f\"Cosine Similarity Score: {similarity_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFdLqnz6Oihg",
        "outputId": "4bef6e5f-9c94-4fca-d3f3-d46ea7c7fba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity Score: 0.18314741859825204\n"
          ]
        }
      ]
    }
  ]
}